{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NMT_jointLearn(Prac).ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPBFavu5N4L4pMh1sKX+SqI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"RrPOfjV-7kvU"},"source":["Attention Based Sequence to Sequence Model.(German-english)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"pV2Vef4Hbp72","executionInfo":{"status":"ok","timestamp":1620352142203,"user_tz":-480,"elapsed":927,"user":{"displayName":"資訊管理系洪英皓","photoUrl":"","userId":"11573378404956526907"}},"outputId":"fdd616c2-648f-40d2-a2b1-b6eb573a62ff"},"source":["import os\n","os.chdir('./gdrive/MyDrive/nl_prac')\n","os.getcwd()"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/gdrive/MyDrive/nl_prac'"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"76rBGCSqhbhZ","executionInfo":{"status":"ok","timestamp":1620352143203,"user_tz":-480,"elapsed":1212,"user":{"displayName":"資訊管理系洪英皓","photoUrl":"","userId":"11573378404956526907"}}},"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torchtext\n","from torch.utils.data import RandomSampler\n","\n","import spacy\n","import numpy as np\n","from nlp_utils import Model_pipeline,set_rnd_seed,init_model_weights,count_parameters\n","\n","import os\n","import time\n","import tqdm\n","import random"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"tqJpZGkXlHnd","executionInfo":{"status":"ok","timestamp":1620353792407,"user_tz":-480,"elapsed":4697,"user":{"displayName":"資訊管理系洪英皓","photoUrl":"","userId":"11573378404956526907"}}},"source":["set_rnd_seed(1234)\n","\n","\n","#set device\n","device=torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n","spacy.require_gpu()\n","#load German & english spacy tokenizer\n","de_nlp=spacy.load('de_core_news_sm')\n","en_nlp=spacy.load('en_core_web_sm')"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"skkOOLGdoLPc"},"source":["Build text *tokenizer* func"]},{"cell_type":"code","metadata":{"id":"RkIrbnUpoQZN","executionInfo":{"status":"ok","timestamp":1620352256832,"user_tz":-480,"elapsed":1029,"user":{"displayName":"資訊管理系洪英皓","photoUrl":"","userId":"11573378404956526907"}}},"source":["def en_tokenizer(text):\n","  return [t.text for t in en_nlp.tokenizer(text)]\n","def de_tokenizer(text):\n","  return [t.text for t in de_nlp.tokenizer(text)]"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gxu9o0KzNG-L"},"source":["# **sequential data的處理步驟**\n","\n","\n","1.   進行tokenize\n","2.   建立各Language的vocabulary(涵蓋special token-<sos>,<eos>,<pad>,<unk>)\n","3.   將一個sequence加入sos,eos special token\n","4.   轉換成index\n"]},{"cell_type":"code","metadata":{"id":"2eCdtsdQpIjj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620352273754,"user_tz":-480,"elapsed":15374,"user":{"displayName":"資訊管理系洪英皓","photoUrl":"","userId":"11573378404956526907"}},"outputId":"fd54a0e2-8080-443a-8ccb-3428e6416a05"},"source":["#build source sents & target field\n","SRC=torchtext.data.Field(init_token='<sos>',eos_token='<eos>',tokenize=de_tokenizer)\n","TRG=torchtext.data.Field(init_token='<sos>',eos_token='<eos>',tokenize=en_tokenizer)\n","#load data\n","train_data,val_data,test_data=torchtext.datasets.Multi30k.splits(('.de','.en'),(SRC,TRG))\n","print(f'Train exmaples num:{len(train_data)}')\n","print(f'Val exmaples num:{len(val_data)}')\n","print(f'test exmaples num:{len(test_data)}')\n","print(f'One example from Train data:{train_data[0].src}')"],"execution_count":14,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n","  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["downloading training.tar.gz\n"],"name":"stdout"},{"output_type":"stream","text":["training.tar.gz: 100%|██████████| 1.21M/1.21M [00:03<00:00, 322kB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["downloading validation.tar.gz\n"],"name":"stdout"},{"output_type":"stream","text":["validation.tar.gz: 100%|██████████| 46.3k/46.3k [00:00<00:00, 90.9kB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["downloading mmt_task1_test2016.tar.gz\n"],"name":"stdout"},{"output_type":"stream","text":["mmt_task1_test2016.tar.gz: 100%|██████████| 66.2k/66.2k [00:00<00:00, 77.5kB/s]\n","/usr/local/lib/python3.7/dist-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n","  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Train exmaples num:29000\n","Val exmaples num:1014\n","test exmaples num:1000\n","One example from Train data:['Zwei', 'junge', 'weiße', 'Männer', 'sind', 'im', 'Freien', 'in', 'der', 'Nähe', 'vieler', 'Büsche', '.']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ddlpId-8sRhx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620353137162,"user_tz":-480,"elapsed":863382,"user":{"displayName":"資訊管理系洪英皓","photoUrl":"","userId":"11573378404956526907"}},"outputId":"0a64c2aa-3e1f-43b6-98f2-2ea04140c866"},"source":["#build vocab\n","SRC.build_vocab(train_data,min_freq=2,vectors='glove.42B.300d')\n","TRG.build_vocab(train_data,min_freq=2,vectors='glove.42B.300d')"],"execution_count":15,"outputs":[{"output_type":"stream","text":[".vector_cache/glove.42B.300d.zip: 1.88GB [05:56, 5.27MB/s]                            \n","100%|█████████▉| 1917135/1917494 [05:01<00:00, 7376.54it/s]"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"eYCsVdfYui7j","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620353137166,"user_tz":-480,"elapsed":863367,"user":{"displayName":"資訊管理系洪英皓","photoUrl":"","userId":"11573378404956526907"}},"outputId":"577528bd-8988-4a79-f75b-be5ba7660649"},"source":["print(f'SRC vocab size:{len(SRC.vocab)}')\n","print(f'TRG vocab size:{len(TRG.vocab)}')\n","#set vocab size embedding weight for glove\n","SRC.vocab.set_vectors(SRC.vocab.stoi,SRC.vocab.vectors,dim=300)\n","TRG.vocab.set_vectors(TRG.vocab.stoi,TRG.vocab.vectors,dim=300)\n","print(f'SRC glove embedding size:{SRC.vocab.vectors.size()}')\n","print(f'TRG glove embedding size:{TRG.vocab.vectors.size()}')"],"execution_count":16,"outputs":[{"output_type":"stream","text":["SRC vocab size:8014\n","TRG vocab size:6191\n","SRC glove embedding size:torch.Size([8014, 300])\n","TRG glove embedding size:torch.Size([6191, 300])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"s8Q3IN9Vwzsj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620353167548,"user_tz":-480,"elapsed":914,"user":{"displayName":"資訊管理系洪英皓","photoUrl":"","userId":"11573378404956526907"}},"outputId":"a3f58d8e-d9a2-46a4-c1c8-81bd9f32d54f"},"source":["#set data iterator\n","Batch_size=256\n","train_iter=torchtext.data.BucketIterator(train_data,batch_size=Batch_size,shuffle=True,device=device)\n","val_iter,test_iter=torchtext.data.BucketIterator.splits((val_data,test_data),batch_size=Batch_size,device=device)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n","  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"69uYy8W5LBUt"},"source":["# **Encoder(Bidirectional)架構**\n","**模型架構**\n","*   輸入-每個時間點的token id\n","*   輸出-每個時間點的h_state,最後一個時間點的不同layer之h_state\n","\n","**演算流程:**\n","\n","對於每個time step的embedding vector，rnn layer來extract當前word的h_state，然後if 雙向RNN，則是Output foward,backward的concat hid"]},{"cell_type":"code","metadata":{"id":"EOztENlHptRn","executionInfo":{"status":"ok","timestamp":1620355450275,"user_tz":-480,"elapsed":955,"user":{"displayName":"資訊管理系洪英皓","photoUrl":"","userId":"11573378404956526907"}}},"source":["#build Encoder Model\n","class BiEncoder(nn.Module):\n","  def __init__(self,input_dim,hid_dim,n_layers,dropout_rate,pretrain_embed=None):\n","    super(BiEncoder,self).__init__()\n","    self.input_dim=input_dim\n","    self.hid_dim=hid_dim\n","    self.n_layers=n_layers\n","\n","    #determined use embed layer whether is pretrained weight or not\n","    if pretrain_embed is None:\n","      self.embed=nn.Embedding(input_dim,hid_dim)\n","    else:\n","      self.embed=nn.Embedding.from_pretrained(pretrain_embed)\n","    self.rnn_layer=nn.GRU(hid_dim,hid_dim,n_layers,dropout=dropout_rate,bidirectional=True)\n","    self.linear_layer=nn.Linear(hid_dim*2,hid_dim)\n","    self.tanh=nn.Tanh()\n","    self.dropout=nn.Dropout(dropout_rate)\n","  def forward(self,input_tensors):\n","    #input tensor shape=[seqL,bs]\n","    embed_input=self.dropout(self.embed(input_tensors))\n","    \n","    outputs,h_state=self.rnn_layer(embed_input)\n","    #output shape=[seq_len,bs,hid_dim*2]\n","    #h_state shape=[layer_num,direction,bs,hid_dim]\n","    #concat forward & backward last layer\n","    h_state=self.tanh(self.linear_layer(torch.cat((h_state[-2,:,:],h_state[-1,:,:]),dim=1)))\n","    return outputs,h_state.unsqueeze(0)"],"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aT-bMY_hqxmC"},"source":["# **Attention match layer**\n","**模型架構**\n","*   輸入-decoder前一次的h_state,encoder每個time step的Repr.(hidden_output)\n","*   輸出-每個time step的attention weight\n","\n","\n","  演算流程:  \n","      將decoder的h_state與每個Repr.的concatenate進行降維，隨後再讓他與一個weight matrix進行inner product，得到的wieght即為前一次h_state對encoder output中的每個Repr之關注程度。\n"]},{"cell_type":"code","metadata":{"id":"rKHtXRNEpF2D","executionInfo":{"status":"ok","timestamp":1620355451850,"user_tz":-480,"elapsed":940,"user":{"displayName":"資訊管理系洪英皓","photoUrl":"","userId":"11573378404956526907"}}},"source":["#build attention Model\n","class Attention(nn.Module):\n","  def __init__(self,hid_dim):\n","    super(Attention,self).__init__()\n","    self.attn_layer=nn.Linear(2*hid_dim+hid_dim,hid_dim)\n","    self.v=nn.Linear(hid_dim,1,bias=False)\n","    self.softmax=nn.Softmax(dim=1)\n","    self.tanh=nn.Tanh()\n","  def forward(self,decoder_hidden,encoder_outputs):\n","    batch_size=encoder_outputs.size(1)\n","    seqLen=encoder_outputs.size(0)\n","\n","    decoder_hidden=decoder_hidden.unsqueeze(1)#insert dim shape=[bs,1,hid_dim]\n","    decoder_hidden=decoder_hidden.repeat(1,seqLen,1)\n","\n","    #concat decoder_hidden & encoder_outputs\n","    #shape=[bs,seqLen,encoder_hid+decoder_hid]\n","    attn_hid=torch.cat((decoder_hidden,encoder_outputs.permute(1,0,2)),dim=2)\n","    #non-linear transform\n","    attn_hid=self.tanh(self.attn_layer(attn_hid))\n","    #compute attnetion weight\n","    #shape=[bs,seqLen]\n","    attn_weight=self.softmax(self.v(attn_hid).squeeze(2))\n","\n","    return attn_weight"],"execution_count":22,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v7eqMDZb-qM3"},"source":["# **建立Decoder**\n","\n","**Decoder架構**\n","*   輸入-前一個時間點decoder輸出的token之Embedding,h_state以及關注encoder ouutput的attention weight,encoder output\n","*   輸出-當前時間點=的word Dist.以及hidden_state\n","\n"," \n"," **演算過程**:\n","  將輸入word的Embedding與Context(將encoder output藉由attention weight來weight sum)進行concat然後輸入至rnn_layer中，隨後將rnn layer的hidden_state與input word embedding,context vector送進linear classifier"]},{"cell_type":"code","metadata":{"id":"dY-LCImVyr5J","executionInfo":{"status":"ok","timestamp":1620355472375,"user_tz":-480,"elapsed":1098,"user":{"displayName":"資訊管理系洪英皓","photoUrl":"","userId":"11573378404956526907"}}},"source":["class Decoder(nn.Module):\n","  def __init__(self,input_dim,hid_dim,output_dim,n_layers,dropout_rate,pretrain_embed=None):\n","    super(Decoder,self).__init__()\n","    self.input_dim=input_dim\n","    self.hid_dim=hid_dim\n","    self.output_dim=output_dim\n","    self.n_layers=n_layers\n","\n","    #determined use embed layer whether is pretrained weight or not\n","    if pretrain_embed is None:\n","      self.embed=nn.Embedding(input_dim,hid_dim)\n","    else:\n","      self.embed=nn.Embedding.from_pretrained(pretrain_embed)\n","    self.rnn_layer=nn.GRU(hid_dim*3,hid_dim,n_layers,dropout=dropout_rate)\n","    self.fc=nn.Linear(hid_dim+hid_dim+hid_dim*2,output_dim)\n","  def forward(self,input_tensors,hidden_state,attn_weight,encoder_outputs):\n","    input_embed=self.embed(input_tensors)\n","    context_vector=torch.bmm(attn_weight.unsqueeze(dim=1),encoder_outputs)[:,0,:]\n","    #compute input rnn tensor and insert dim0\n","    input_tensor=torch.cat((input_embed,context_vector),dim=1).unsqueeze(0)\n","    \n","    outputs,h_state=self.rnn_layer(input_tensor,hidden_state)\n","    #output shape=[bs,output_dim]\n","    outputs=self.fc(torch.cat((input_embed,context_vector,outputs[0]),dim=1))\n","    return outputs,h_state"],"execution_count":24,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rAgbLTeXJBfo"},"source":["# **Sequence to Sequence Model(Coditional Generation)**\n","\n","模型架構\n","\n","\n","*   輸入-source sentences index.\n","*   輸出-target sentences index.\n","\n","演算流程\n"," \n","\n","1.   將src sents 透過encoder進行encoding,得到該sent每個word的Repr. 以及 最後一個time step的hidden state\n","2.   將context vector視為最初要輸入至decoder的hidden state，sos token id則設置為第一個要輸入至decoder的word token\n","3.   以下流程則是反覆iter seqlen+1次\n","    \n","\n","*   使用attention layer計算前一次h_state與encoder output的attention\n","*   將得到的attention weight與encoder output進行weighted sum得到context vector\n","*   將context vector、前一次decoder 預測的詞彙之word embedding & h_sate輸入至decoder中\n","*   將當前decoder輸出的h_state 與前一次的word embedding以及context vector輸入至linear classifier\n","*   將Linear classifier的output以及當前計算的h_state當作是下一個decoder要輸入的word,h_state\n","\n","\n","\n","\n"," "]},{"cell_type":"code","metadata":{"id":"iQ0NFtauJApG","executionInfo":{"status":"ok","timestamp":1620355475291,"user_tz":-480,"elapsed":1165,"user":{"displayName":"資訊管理系洪英皓","photoUrl":"","userId":"11573378404956526907"}}},"source":["class AttnSeq2Seq(nn.Module):\n","  def __init__(self,encoder,decoder,attner,device,pad_idx):\n","    super(AttnSeq2Seq,self).__init__()\n","    self.encoder=encoder\n","    self.decoder=decoder\n","    self.attner=attner\n","    self.device=device\n","    self.criterion=nn.CrossEntropyLoss(ignore_index=pad_idx)\n","    assert self.encoder.hid_dim==self.decoder.hid_dim\n","  def forward(self,src,trg=None,teach_ratio=0.5):\n","    seqLen=trg.size(0)\n","    Batch_size=trg.size(1)\n","    OutputVocab=self.decoder.output_dim\n","    preds=torch.zeros(seqLen,Batch_size,OutputVocab,device=self.device)\n","    #get seq hidden vector and Context vector\n","    encoder_outputs,final_hidden=self.encoder(src)\n","\n","    decoder_hidden=final_hidden\n","    decoder_input=trg[0,:]\n","    for ti in range(1,seqLen):\n","      #compute attention weight\n","      #shape=[bs,seqLen]\n","      attn_weight=self.attner(decoder_hidden[-1,:,:],encoder_outputs)\n","      #output vector,shape=[bs,vocab]\n","      #decoder hidden,shape=[n_layers,bs,hid_dim]\n","      decoder_outputs,decoder_hidden=self.decoder(decoder_input,decoder_hidden,attn_weight,encoder_outputs.permute(1,0,2))\n","      preds[ti]=decoder_outputs\n","      \n","      #determined next input using teacher forcing or not\n","      teach_force=True if random.random()<teach_ratio else False\n","      top1=decoder_outputs.argmax(dim=1)\n","      decoder_input=trg[ti] if teach_force else top1\n","\n","    loss=None\n","    if trg is not None:\n","      #output=[seqLen*Bs,class_num]\n","      #labels=[seqlen*Bs,]\n","      outputs=preds[1:,:,:].reshape(-1,OutputVocab)\n","      labels=trg[1:,:].reshape(-1)\n","      loss=self.criterion(outputs,labels)\n","    #preds shape=[seq_len,bs,vocab_dim]\n","    return preds,loss\n","  def getPredict(self,src_tensors,trg_initTokenId,end_tokenId):\n","    preds=[]\n","\n","    #get hidden_vector,context vector\n","    encoder_outputs,final_hidden=self.encoder(src_tensors)\n","    decoder_hidden=final_hidden\n","    decoder_input=torch.tensor([trg_initTokenId],device=self.device)\n","    \n","    while True:\n","      #compute attention weight\n","      attn_weight=self.attner(decoder_hidden[-1,:,:],encoder_outputs)\n","      \n","      #output\n","      decoder_outputs,decoder_hidden=self.decoder(decoder_input,decoder_hidden,attn_weight,encoder_outputs.permute(1,0,2))\n","\n","      top1=decoder_outputs.argmax(dim=1)\n","      decoder_input=top1\n","      #append to preds\n","      preds.append(decoder_input.item())\n","      if decoder_input.item()==end_tokenId:\n","        break\n","    #return list of token id\n","    return preds"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"HEolBLirmqW9","executionInfo":{"status":"ok","timestamp":1620358188535,"user_tz":-480,"elapsed":1006,"user":{"displayName":"資訊管理系洪英皓","photoUrl":"","userId":"11573378404956526907"}}},"source":["def get_evaluate(model,eval_data,de_field,en_field,device):\n","  #random sampling example from eval_data\n","  idx=random.choice(range(0,len(eval_data)))\n","  eval_example=eval_data.examples[idx]\n","  src_sents=['<sos>']+eval_example.src+['<eos>']\n","  trg_sents=eval_example.trg\n","  #convert tensors shape=[seqLen,batch]\n","  src_tensors=de_field.numericalize([src_sents],device=device)\n","  print(f'Origin eval sents:{src_sents}')\n","\n","  #translate sent\n","  model.eval()\n","  with torch.no_grad():\n","    pred_index=model.getPredict(src_tensors,en_field.vocab.stoi['<sos>'],en_field.vocab.stoi['<eos>'])\n","  pred_sent=[en_field.vocab.itos[id] for id in pred_index if en_field.vocab.itos[id]!='<eos>']\n","\n","  print(f'Original target sents:{trg_sents}')\n","  print(f'Translated target sents:{pred_sent}')"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"9P0Qg-J4wMD5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620361801491,"user_tz":-480,"elapsed":1140,"user":{"displayName":"資訊管理系洪英皓","photoUrl":"","userId":"11573378404956526907"}},"outputId":"7a55ddac-1041-4d8d-8a2e-69bc41f437fa"},"source":["#define Model\n","encoder_config={'input_dim':len(SRC.vocab),'hid_dim':256,\n","        'n_layers':2,'dropout_rate':0.3,\n","        'pretrain_embed':None}\n","decoder_config={'input_dim':len(TRG.vocab),'hid_dim':256,\n","        'output_dim':len(TRG.vocab),'n_layers':1,\n","        'dropout_rate':0,'pretrain_embed':None}\n","attner_config={'hid_dim':256}\n","EPOCHS=70\n","GRAD_NORM=1\n","pad_idx=TRG.vocab.stoi['<pad>']\n","Learning_rate=1e-3\n","model_dir='./MTmodel'\n","model_path='fra2eng_model.pt'\n","\n","model_configs={\n","    'encoder':encoder_config,\n","    'decoder':decoder_config,\n","    'attner':attner_config,\n","    'pad_idx':pad_idx,\n","}\n","\n","#build Model\n","encoder_model=BiEncoder(**encoder_config)\n","decoder_model=Decoder(**decoder_config)\n","attn_model=Attention(**attner_config)\n","model=AttnSeq2Seq(encoder_model,decoder_model,attn_model,device,pad_idx=pad_idx)\n","model.to(device)\n","model.apply(init_model_weights)\n","#build optimizer &loss func\n","optimizer=torch.optim.Adam(model.parameters(),lr=Learning_rate)\n","\n","print('Model total params:{}'.format(count_parameters(model)))"],"execution_count":43,"outputs":[{"output_type":"stream","text":["Model total params:13070895\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_nTFx-j8u_o1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620363988757,"user_tz":-480,"elapsed":2185960,"user":{"displayName":"資訊管理系洪英皓","photoUrl":"","userId":"11573378404956526907"}},"outputId":"0eb41b0d-c780-43bb-a6a7-7d5f5caff671"},"source":["#build pipeline\n","train_pipe=Model_pipeline(model,train_iter,optimizer,None,val_iter,model_configs)\n","train_pipe.amp_training(EPOCHS,model_dir,'src','trg',max_norm=1,teach_ratio=0.5,per_ep_eval=0)"],"execution_count":44,"outputs":[{"output_type":"stream","text":["\n","EPOCHS:   0%|          | 0/70 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n","  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Model dir already existed\n","[1/70] training loss:                   5.351160438437211\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:   1%|▏         | 1/70 [00:31<35:49, 31.15s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[2/70] training loss:                   4.425472556499013\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:   3%|▎         | 2/70 [01:02<35:22, 31.21s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[3/70] training loss:                   4.130690794242056\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:   4%|▍         | 3/70 [01:33<34:43, 31.10s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[4/70] training loss:                   3.8972834746042886\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:   6%|▌         | 4/70 [02:04<34:16, 31.16s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[5/70] training loss:                   3.6236027562827395\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:   7%|▋         | 5/70 [02:35<33:46, 31.18s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[6/70] training loss:                   3.3036988597167167\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:   9%|▊         | 6/70 [03:07<33:25, 31.34s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[7/70] training loss:                   2.9751720679433724\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  10%|█         | 7/70 [03:38<32:52, 31.31s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[8/70] training loss:                   2.701392546034696\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  11%|█▏        | 8/70 [04:09<32:17, 31.25s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[9/70] training loss:                   2.474060853322347\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  13%|█▎        | 9/70 [04:41<31:50, 31.32s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[10/70] training loss:                   2.268858304149226\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  14%|█▍        | 10/70 [05:13<31:35, 31.60s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[11/70] training loss:                   2.0678740060120298\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  16%|█▌        | 11/70 [05:45<31:02, 31.56s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[12/70] training loss:                   1.9359404235555415\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  17%|█▋        | 12/70 [06:16<30:26, 31.49s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[13/70] training loss:                   1.8277555244010792\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  19%|█▊        | 13/70 [06:47<29:48, 31.37s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[14/70] training loss:                   1.7079379903642755\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  20%|██        | 14/70 [07:18<29:12, 31.30s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[15/70] training loss:                   1.6187288844794558\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  21%|██▏       | 15/70 [07:49<28:39, 31.27s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[16/70] training loss:                   1.5295341046232926\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  23%|██▎       | 16/70 [08:21<28:08, 31.27s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[17/70] training loss:                   1.4728523105905766\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  24%|██▍       | 17/70 [08:52<27:39, 31.30s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[18/70] training loss:                   1.420649786790212\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  26%|██▌       | 18/70 [09:23<27:05, 31.26s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[19/70] training loss:                   1.3535083605532061\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  27%|██▋       | 19/70 [09:54<26:33, 31.24s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[20/70] training loss:                   1.3016763925552368\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  29%|██▊       | 20/70 [10:26<26:05, 31.31s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[21/70] training loss:                   1.2204064779114305\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  30%|███       | 21/70 [10:57<25:31, 31.25s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[22/70] training loss:                   1.1711236918181704\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  31%|███▏      | 22/70 [11:28<24:58, 31.21s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[23/70] training loss:                   1.138314986438082\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  33%|███▎      | 23/70 [11:59<24:26, 31.21s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[24/70] training loss:                   1.0993932909087132\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  34%|███▍      | 24/70 [12:30<23:53, 31.16s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[25/70] training loss:                   1.0670770364895201\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  36%|███▌      | 25/70 [13:02<23:27, 31.28s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[26/70] training loss:                   0.9904010865771979\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  37%|███▋      | 26/70 [13:33<22:57, 31.31s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[27/70] training loss:                   0.9734097719192505\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  39%|███▊      | 27/70 [14:04<22:22, 31.21s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[28/70] training loss:                   0.9673836173718435\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  40%|████      | 28/70 [14:35<21:49, 31.17s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[29/70] training loss:                   0.8922524426067084\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  41%|████▏     | 29/70 [15:07<21:19, 31.21s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[30/70] training loss:                   0.9008331445225498\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  43%|████▎     | 30/70 [15:38<20:47, 31.19s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[31/70] training loss:                   0.833664123426404\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  44%|████▍     | 31/70 [16:09<20:17, 31.21s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[32/70] training loss:                   0.8212109140136785\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  46%|████▌     | 32/70 [16:40<19:47, 31.24s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[33/70] training loss:                   0.8044969575446949\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  47%|████▋     | 33/70 [17:12<19:21, 31.38s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[34/70] training loss:                   0.7800719884403965\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  49%|████▊     | 34/70 [17:43<18:48, 31.34s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[35/70] training loss:                   0.7604020180409414\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  50%|█████     | 35/70 [18:15<18:21, 31.46s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[36/70] training loss:                   0.7224832773208618\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  51%|█████▏    | 36/70 [18:46<17:43, 31.29s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[37/70] training loss:                   0.699154008375971\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  53%|█████▎    | 37/70 [19:17<17:11, 31.27s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[38/70] training loss:                   0.6906261846684573\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  54%|█████▍    | 38/70 [19:48<16:38, 31.20s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[39/70] training loss:                   0.6872122716485408\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  56%|█████▌    | 39/70 [20:19<16:06, 31.19s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[40/70] training loss:                   0.631361142846576\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  57%|█████▋    | 40/70 [20:51<15:38, 31.27s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[41/70] training loss:                   0.6250406725887667\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  59%|█████▊    | 41/70 [21:22<15:06, 31.25s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[42/70] training loss:                   0.6124159615290793\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  60%|██████    | 42/70 [21:53<14:33, 31.21s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[43/70] training loss:                   0.6027265371460664\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  61%|██████▏   | 43/70 [22:24<14:03, 31.23s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[44/70] training loss:                   0.5668498214922453\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  63%|██████▎   | 44/70 [22:56<13:33, 31.27s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[45/70] training loss:                   0.5545815679064968\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  64%|██████▍   | 45/70 [23:27<13:01, 31.24s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[46/70] training loss:                   0.5269413917211064\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  66%|██████▌   | 46/70 [23:58<12:30, 31.27s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[47/70] training loss:                   0.5155393238130369\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  67%|██████▋   | 47/70 [24:30<12:00, 31.31s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[48/70] training loss:                   0.5116030273207447\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  69%|██████▊   | 48/70 [25:01<11:30, 31.39s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[49/70] training loss:                   0.4730681502505353\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  70%|███████   | 49/70 [25:33<10:59, 31.41s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[50/70] training loss:                   0.4639512452117184\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  71%|███████▏  | 50/70 [26:04<10:26, 31.32s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[51/70] training loss:                   0.45877804986217563\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  73%|███████▎  | 51/70 [26:35<09:55, 31.32s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[52/70] training loss:                   0.4675797150846113\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  74%|███████▍  | 52/70 [27:06<09:20, 31.16s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[53/70] training loss:                   0.4509265945668806\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  76%|███████▌  | 53/70 [27:37<08:49, 31.14s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[54/70] training loss:                   0.4342719596206096\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  77%|███████▋  | 54/70 [28:08<08:18, 31.13s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[55/70] training loss:                   0.42633265910441415\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  79%|███████▊  | 55/70 [28:39<07:46, 31.10s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[56/70] training loss:                   0.4056122948726018\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  80%|████████  | 56/70 [29:10<07:15, 31.09s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[57/70] training loss:                   0.3803158120105141\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  81%|████████▏ | 57/70 [29:41<06:43, 31.06s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[58/70] training loss:                   0.37167666577979136\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  83%|████████▎ | 58/70 [30:13<06:13, 31.14s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[59/70] training loss:                   0.37454060059890415\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  84%|████████▍ | 59/70 [30:43<05:41, 31.06s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[60/70] training loss:                   0.3656554904423262\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  86%|████████▌ | 60/70 [31:14<05:10, 31.02s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[61/70] training loss:                   0.36635740336618927\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  87%|████████▋ | 61/70 [31:45<04:38, 30.98s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[62/70] training loss:                   0.34608043612618195\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  89%|████████▊ | 62/70 [32:16<04:07, 30.99s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[63/70] training loss:                   0.36131198665029124\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  90%|█████████ | 63/70 [32:47<03:36, 30.97s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[64/70] training loss:                   0.3283959601009101\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  91%|█████████▏| 64/70 [33:18<03:05, 30.94s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[65/70] training loss:                   0.3165012492161048\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  93%|█████████▎| 65/70 [33:49<02:34, 30.92s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[66/70] training loss:                   0.3021888757745425\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  94%|█████████▍| 66/70 [34:20<02:03, 30.91s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[67/70] training loss:                   0.29470028166185347\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  96%|█████████▌| 67/70 [34:51<01:33, 31.02s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[68/70] training loss:                   0.3011055354747856\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  97%|█████████▋| 68/70 [35:22<01:01, 30.97s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[69/70] training loss:                   0.2838251220813969\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS:  99%|█████████▊| 69/70 [35:53<00:30, 30.94s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n","[70/70] training loss:                   0.29845728280774336\n","Start save Model to dir:./MTmodel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","EPOCHS: 100%|██████████| 70/70 [36:24<00:00, 31.21s/it]"],"name":"stderr"},{"output_type":"stream","text":["Save Model success!\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["([5.351160438437211,\n","  4.425472556499013,\n","  4.130690794242056,\n","  3.8972834746042886,\n","  3.6236027562827395,\n","  3.3036988597167167,\n","  2.9751720679433724,\n","  2.701392546034696,\n","  2.474060853322347,\n","  2.268858304149226,\n","  2.0678740060120298,\n","  1.9359404235555415,\n","  1.8277555244010792,\n","  1.7079379903642755,\n","  1.6187288844794558,\n","  1.5295341046232926,\n","  1.4728523105905766,\n","  1.420649786790212,\n","  1.3535083605532061,\n","  1.3016763925552368,\n","  1.2204064779114305,\n","  1.1711236918181704,\n","  1.138314986438082,\n","  1.0993932909087132,\n","  1.0670770364895201,\n","  0.9904010865771979,\n","  0.9734097719192505,\n","  0.9673836173718435,\n","  0.8922524426067084,\n","  0.9008331445225498,\n","  0.833664123426404,\n","  0.8212109140136785,\n","  0.8044969575446949,\n","  0.7800719884403965,\n","  0.7604020180409414,\n","  0.7224832773208618,\n","  0.699154008375971,\n","  0.6906261846684573,\n","  0.6872122716485408,\n","  0.631361142846576,\n","  0.6250406725887667,\n","  0.6124159615290793,\n","  0.6027265371460664,\n","  0.5668498214922453,\n","  0.5545815679064968,\n","  0.5269413917211064,\n","  0.5155393238130369,\n","  0.5116030273207447,\n","  0.4730681502505353,\n","  0.4639512452117184,\n","  0.45877804986217563,\n","  0.4675797150846113,\n","  0.4509265945668806,\n","  0.4342719596206096,\n","  0.42633265910441415,\n","  0.4056122948726018,\n","  0.3803158120105141,\n","  0.37167666577979136,\n","  0.37454060059890415,\n","  0.3656554904423262,\n","  0.36635740336618927,\n","  0.34608043612618195,\n","  0.36131198665029124,\n","  0.3283959601009101,\n","  0.3165012492161048,\n","  0.3021888757745425,\n","  0.29470028166185347,\n","  0.3011055354747856,\n","  0.2838251220813969,\n","  0.29845728280774336],\n"," [])"]},"metadata":{"tags":[]},"execution_count":44}]},{"cell_type":"markdown","metadata":{"id":"zIc04acR4Gtv"},"source":["# Inference Stage \n","### 德文翻譯英文成果"]},{"cell_type":"code","metadata":{"id":"-CRVigRGxQ2z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620366685168,"user_tz":-480,"elapsed":992,"user":{"displayName":"資訊管理系洪英皓","photoUrl":"","userId":"11573378404956526907"}},"outputId":"1ed3d223-a895-4094-9647-ae13e96aa46d"},"source":["#loading Model in given path\n","# model_ckp=load_modelState(model_dir,model_path,device)\n","# model_configs=load_modelState(model_dir,config_path,device)\n","# encoder_model=BiEncoder(**model_configs['encoder'])\n","# decoder_model=Decoder(**model_configs['decoder'])\n","# attn_model=Attention(**model_configs['attner'])\n","# model=AttnSeq2Seq(encoder_model,decoder_model,attn_model,device)\n","# model.load_state_dict(model_ckp['model'])\n","\n","#using test_data to evaluate Model\n","get_evaluate(model,test_data,SRC,TRG,device)"],"execution_count":46,"outputs":[{"output_type":"stream","text":["Origin eval sents:['<sos>', 'Ein', 'Mann', 'lädt', 'gebackene', 'Brezeln', 'auf', 'einen', 'Koffer-LKW', '.', '<eos>']\n","Original target sents:['A', 'man', 'is', 'loading', 'a', 'box', 'truck', 'with', 'lots', 'of', 'baked', 'pretzels', '.']\n","Translated target sents:['A', 'man', 'is', 'loading', '<unk>', 'makeup', 'in', 'a', 'metal', 'fence', '.']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"IQfa_A5SMthK"},"source":["可修該的不同方法\n","1.init Embedding,GLoVe,fastText\n","2.Gated Rucurrent Unit\n"," Layer-2,3\n"," hid_dim-256\n","3.輸出到Decoder的context vector 的策略\n","  3.1.將第一層,最後一層layer的forward,backward h_state進行concat,然後non-linear transform (tanh)\n","  3.2採用forward or backward的每層layer h_state進行concat transform or pooling(Max,average)\n","  3.3只採用backward or forward 的第一、最後一層layer h_state"]}]}